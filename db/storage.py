# üìÑ –§–∞–π–ª: storage.py
# üìÇ –ü—É—Ç—å: db/
# üìå –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö PostgreSQL —Å pgvector, –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–µ–ø–ª–∏–∫–∏, –ø—É–ª–∞–º–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π, –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ –±–µ–∑–æ–ø–∞—Å–Ω—ã–º –¥–æ—Å—Ç—É–ø–æ–º –∫ —Å–µ—Å—Å–∏—è–º

import os
import time
import logging
from contextlib import contextmanager

from sqlalchemy import create_engine, text, exc
from sqlalchemy.orm import sessionmaker, scoped_session
from sqlalchemy.pool import QueuePool
from sqlalchemy.event import listens_for

from prometheus_client import Gauge, Histogram

from db.models import Base

# üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger("db.storage")
logging.basicConfig(level=os.getenv("LOG_LEVEL", "INFO"))

# üìä –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
DB_CONNECTIONS = Gauge("db_connections", "Active database connections")
DB_QUERY_TIME = Histogram("db_query_time", "DB query time (seconds)")

# ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
class DatabaseConfig:
    def __init__(self):
        self.db_type = os.getenv("DB_TYPE", "postgresql")
        self.user = os.getenv("DB_USER", "librarian")
        self.password = os.getenv("DB_PASSWORD", "secretpass")
        self.host = os.getenv("DB_HOST", "localhost")
        self.port = os.getenv("DB_PORT", "5432")
        self.name = os.getenv("DB_NAME", "librarian_db")
        self.replica_host = os.getenv("DB_REPLICA_HOST")
        self.pool_size = int(os.getenv("DB_POOL_SIZE", 20))
        self.max_overflow = int(os.getenv("DB_MAX_OVERFLOW", 10))
        self.timeout = int(os.getenv("DB_TIMEOUT", 30))

    def get_master_url(self):
        if self.db_type == "postgresql":
            return f"postgresql+psycopg2://{self.user}:{self.password}@{self.host}:{self.port}/{self.name}"
        return "sqlite:///storage/librarian.db"

    def get_replica_url(self):
        if self.replica_host:
            return f"postgresql+psycopg2://{self.user}:{self.password}@{self.replica_host}:{self.port}/{self.name}"
        return None

# üß† –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ë–î
db_config = DatabaseConfig()

# üöÄ –°–æ–∑–¥–∞–Ω–∏–µ –¥–≤–∏–∂–∫–æ–≤
def create_engine_with_config(url, **kwargs):
    return create_engine(
        url,
        poolclass=QueuePool,
        pool_pre_ping=True,
        pool_size=db_config.pool_size,
        max_overflow=db_config.max_overflow,
        pool_timeout=db_config.timeout,
        connect_args={"connect_timeout": db_config.timeout},
        **kwargs
    )

engine = create_engine_with_config(
    db_config.get_master_url(),
    echo=os.getenv("DB_ECHO", "false").lower() == "true"
)

replica_engine = None
if db_config.get_replica_url():
    replica_engine = create_engine_with_config(db_config.get_replica_url(), echo=False)

# üîÅ –°–µ—Å—Å–∏–∏
SessionLocal = sessionmaker(bind=engine, autocommit=False, autoflush=False, expire_on_commit=False)
ReplicaSessionLocal = sessionmaker(bind=replica_engine if replica_engine else engine, autocommit=False, autoflush=False, expire_on_commit=False)
ScopedSession = scoped_session(SessionLocal)

# üì¶ –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä
@contextmanager
def session_scope(replica=False):
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å —Å–µ—Å—Å–∏–µ–π –ë–î"""
    session = ReplicaSessionLocal() if replica and replica_engine else SessionLocal()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"[DB] –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏: {e}")
        raise
    finally:
        session.close()

# üèóÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
def init_db():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π"""
    try:
        with engine.connect() as conn:
            if engine.url.drivername.startswith("postgresql"):
                extensions = ["vector", "pg_trgm", "hstore", "pg_stat_statements"]
                for ext in extensions:
                    try:
                        conn.execute(text(f"CREATE EXTENSION IF NOT EXISTS {ext}"))
                        logger.info(f"[DB] –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ {ext} ‚Äî –≥–æ—Ç–æ–≤–æ.")
                    except exc.ProgrammingError as e:
                        logger.warning(f"[DB] –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å {ext}: {e}")
            conn.execute(text("SET statement_timeout = '30s'"))
        Base.metadata.create_all(bind=engine)
        logger.info("‚úÖ –¢–∞–±–ª–∏—Ü—ã –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã.")
    except exc.OperationalError as e:
        logger.critical(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        raise

# üìà –ú–µ—Ç—Ä–∏–∫–∏ Prometheus (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
@listens_for(engine, "connect")
def track_connections(dbapi_connection, connection_record):
    DB_CONNECTIONS.inc()

@listens_for(engine, "close")
def track_disconnections(dbapi_connection, connection_record):
    DB_CONNECTIONS.dec()

@listens_for(engine, "before_cursor_execute")
def before_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    context._query_start_time = time.time()

@listens_for(engine, "after_cursor_execute")
def after_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    duration = time.time() - context._query_start_time
    DB_QUERY_TIME.observe(duration)
