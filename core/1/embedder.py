# üìÑ –§–∞–π–ª: embedder.py | –†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ: librarian_ai/core/embedder.py
# üìå –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è FAISS
# üì• –ü–æ–ª—É—á–∞–µ—Ç: —Å–ø–∏—Å–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤ (–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö)
# üì§ –ü–µ—Ä–µ–¥–∞—ë—Ç: numpy-–≤–µ–∫—Ç–æ—Ä—ã, –∏–Ω–¥–µ–∫—Å FAISS –∏ –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

from sentence_transformers import SentenceTransformer
import numpy as np
import faiss
import os
import pickle

class Embedder:
    def __init__(self, model_name="all-MiniLM-L6-v2"):
        self.model = SentenceTransformer(model_name)

    def encode(self, texts):
        """
        –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤
        :param texts: List[str]
        :return: np.array –≤–µ–∫—Ç–æ—Ä–æ–≤
        """
        return self.model.encode(texts, convert_to_numpy=True)

    def save_index(self, vectors, metadata, index_path="knowledge/vector_store/index.faiss", meta_path="knowledge/vector_store/meta.pkl"):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç FAISS-–∏–Ω–¥–µ–∫—Å –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        :param vectors: np.array
        :param metadata: List[dict]
        """
        dim = vectors.shape[1]
        index = faiss.IndexFlatL2(dim)
        index.add(vectors)
        faiss.write_index(index, index_path)

        with open(meta_path, "wb") as f:
            pickle.dump(metadata, f)

        print(f"üíæ –ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {index_path}, –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ ‚Äî –≤ {meta_path}")


if __name__ == "__main__":
    texts = ["–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "–ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", "–ì–û–°–¢ 57580"]
    meta = [
        {"source": "doc1.txt", "text": texts[0]},
        {"source": "doc2.txt", "text": texts[1]},
        {"source": "doc3.txt", "text": texts[2]},
    ]
    embedder = Embedder()
    vecs = embedder.encode(texts)
    embedder.save_index(vecs, meta)
