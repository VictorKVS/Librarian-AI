# üìÑ –§–∞–π–ª: core/tools/async_tasks.py
# üìå –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ Celery –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫

import asyncio
from pathlib import Path
from typing import Union, Dict, Optional
from celery import Celery
from celery.exceptions import Reject
from core.parser.chunker import TextChunker
from core.tools.loader import FileLoader
from models import ProcessingResult
import logging

logger = logging.getLogger(__name__)

# üîó –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Celery —Å Redis
celery = Celery(
    "librarian",
    broker="redis://localhost:6379/0",
    backend="redis://localhost:6379/1",
    task_track_started=True,
    result_extended=True
)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–¥–∞—á
celery.conf.update(
    task_serializer='json',
    result_serializer='json',
    accept_content=['json'],
    task_acks_late=True,
    task_reject_on_worker_lost=True,
    task_time_limit=300,  # 5 –º–∏–Ω—É—Ç –Ω–∞ –∑–∞–¥–∞—á—É
    task_soft_time_limit=240  # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ —á–µ—Ä–µ–∑ 4 –º–∏–Ω—É—Ç—ã
)

class FileProcessor:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤"""
    
    def __init__(self):
        self.chunker = TextChunker()
        self.loader = FileLoader(self.chunker)
    
    def load_file_sync(
        self,
        file_path: Union[str, Path],
        chunk_size: int = 1000,
        max_chunks: Optional[int] = None,
        language: str = "auto"
    ) -> ProcessingResult:
        """
        –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            chunk_size: –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–æ–≤ –≤ —Å–∏–º–≤–æ–ª–∞—Ö
            max_chunks: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤
            language: –Ø–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞ (auto –¥–ª—è –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)
        Returns:
            ProcessingResult —Å —á–∞–Ω–∫–∞–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        try:
            return asyncio.run(
                self.loader.load_file(
                    str(file_path),
                    chunk_size=chunk_size,
                    max_chunks=max_chunks,
                    language=language
                )
            )
        except Exception as e:
            logger.error(f"Failed to process {file_path}: {str(e)}")
            raise

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
processor = FileProcessor()

@celery.task(
    bind=True,
    autoretry_for=(Exception,),
    retry_backoff=3,
    retry_kwargs={'max_retries': 3},
    rate_limit='10/m'  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: 10 –∑–∞–¥–∞—á –≤ –º–∏–Ω—É—Ç—É
)
def process_file_task(self, file_path: str, user_id: Optional[str] = None) -> Dict:
    """
    –§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    Args:
        file_path: –ê–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
        user_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    try:
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏
        self.update_state(
            state='PROGRESS',
            meta={'status': 'Analyzing file', 'progress': 10}
        )
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        result = processor.load_file_sync(file_path)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics = {
            'filename': Path(file_path).name,
            'file_size': result.metadata.size,
            'chunk_count': len(result.chunks),
            'language': result.metadata.language,
            'processing_time': round(result.processing_time, 2),
            'user_id': user_id
        }
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—Ö–∞
        logger.info(f"Successfully processed {file_path}")
        return metrics
        
    except Exception as e:
        logger.error(f"Task failed for {file_path}: {str(e)}")
        # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–¥–∞—á–∏ –≤ –æ—á–µ—Ä–µ–¥—å –º–µ—Ä—Ç–≤—ã—Ö –ø–∏—Å–µ–º –ø–æ—Å–ª–µ 3 –ø–æ–ø—ã—Ç–æ–∫
        if self.request.retries == self.max_retries:
            self.send_event(
                'task-failed',
                exception=str(e),
                filename=file_path
            )
        raise Reject(str(e), requeue=False)

@celery.task
def cleanup_temp_files(file_paths: List[str]):
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    for path in file_paths:
        try:
            Path(path).unlink(missing_ok=True)
        except Exception as e:
            logger.warning(f"Failed to delete {path}: {str(e)}")

def create_chain(file_paths: List[str], user_id: str) -> Dict:
    """
    –°–æ–∑–¥–∞–µ—Ç —Ü–µ–ø–æ—á–∫—É –∑–∞–¥–∞—á –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å ID –∫–æ—Ä–Ω–µ–≤–æ–π –∑–∞–¥–∞—á–∏ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ñ–∞–π–ª–æ–≤
    """
    chain = (
        process_file_task.s(file_path, user_id)
        for file_path in file_paths
    )
    result = celery.chain(chain).apply_async()
    return {
        'task_id': result.parent.id,
        'file_count': len(file_paths)
    }