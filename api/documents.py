# üìÑ –§–∞–π–ª: documents.py | –†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ: librarian_ai/api/documents.py
# üìå –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: REST API –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏, –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
# üì• –ü–æ–ª—É—á–∞–µ—Ç: —Ñ–∞–π–ª –∏–ª–∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
# üì§ –ü–µ—Ä–µ–¥–∞—ë—Ç: —Å—Ç–∞—Ç—É—Å, —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏, ID –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –±–∞–∑–µ

from fastapi import APIRouter, UploadFile, File
from librarian_ai.core.loader import load_documents
from librarian_ai.core.parser import parse_text_file
from librarian_ai.core.embedder import Embedder
from librarian_ai.core.storage import save_to_db
import os

router = APIRouter()
embedder = Embedder()

@router.post("/upload/")
async def upload_document(file: UploadFile = File(...)):
    temp_path = f"temp/{file.filename}"
    os.makedirs("temp", exist_ok=True)
    
    with open(temp_path, "wb") as f:
        content = await file.read()
        f.write(content)

    parsed = parse_text_file(temp_path)
    if "text" not in parsed:
        return {"error": parsed.get("error", "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ")}

    chunks = [parsed["text"][i:i+3000] for i in range(0, len(parsed["text"]), 3000)]
    vectors = embedder.encode(chunks)
    meta = [{"filename": parsed["meta"]["filename"], "chunk": i} for i in range(len(chunks))]

    embedder.save_index(vectors, meta)
    save_to_db(parsed["text"], parsed["meta"])

    os.remove(temp_path)
    return {"status": "ok", "chunks": len(chunks), "filename": parsed["meta"]["filename"]}
